{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\n",
      "ERROR: No matching distribution found for upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (74.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tqdm_joblib in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (0.0.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tqdm in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm_joblib) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm->tqdm_joblib) (0.4.6)\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-optimize) (1.4.2)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-optimize) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-optimize) (1.5.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-optimize) (24.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cpedr\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
      "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "Downloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas matplotlib numpy scikit-learn ace_tools panelsplit shap upgrade jupyter ipywidgets \n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install tqdm_joblib\n",
    "%pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cpedr\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.add_dll_directory(r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\\bin\")\n",
    "import thundersvm\n",
    "from thundersvm import SVR \n",
    "import torch\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "from panelsplit.cross_validation import PanelSplit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from tqdm import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "# Check number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(\"Number of CPU cores available:\", num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file names\n",
    "csv_filename = \"../final_df.csv\"\n",
    "zip_filename = \"../final_df.zip\"\n",
    "\n",
    "# Extract the CSV file from the ZIP\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zipf:\n",
    "    zipf.extract(csv_filename)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "final_df = pd.read_csv(\"final_df.csv\")\n",
    "\n",
    "# Delete the extracted CSV file after reading\n",
    "os.remove(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "#Getting rid of redundant columns\n",
    "# X final\n",
    "X1 = final_df.drop(columns=['year', 'codmpio', 'cluster_kmeans', 'Departamento', 'Municipio', 'Region', 'pc_loss', 'f_loss', 'areaoficialhm2', 'gdp']) # GDP, area already out since the were already considered\n",
    "X1 = X1.drop(columns=['CV-01-15','CV-03-64', 'CV-03-26b', 'CV-01-11', 'CV-01-1', 'PCC-02-0', 'PCC-02-3', 'EIS-00-0', 'PCC-00-0', 'CTI-00-0', 'C-02-8t', 'ICM-00-0',\n",
    "                      'EIS-03-4', 'CTI-01-3', 'SEG-00-0', 'SEG-01-6', 'SOS-00-0', 'SOS-02-0', 'SOS-02-2', 'SOS-01-6', 'GPI-00-0', 'GPI-02-4', 'GPI-02-5', 'P-01-34-1',\n",
    "                      'P-01-46', 'P-01-25', 'CV-02-12e', 'CV-03-51', 'total_ac']) \n",
    "\n",
    "print(len(X1.columns))\n",
    "# Keep feature names\n",
    "original_feature_names = list(X1.columns) \n",
    "\n",
    "# y \n",
    "y = final_df['pc_loss']\n",
    "y = np.log1p(final_df['pc_loss'])\n",
    "\n",
    "# Normalize output\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folds with ThunderSVM: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost with PanelSplit Results:\n",
      "ðŸ“Š Avg MSE: 0.0078\n",
      "ðŸ“Š Avg RMSE: 0.0882\n",
      "ðŸ“Š Avg MAE: 0.0640\n",
      "ðŸ“Š Avg RÂ² (Train): 0.5477\n",
      "ðŸ“Š Avg RÂ² (Test): 0.3504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "seed_value = 17\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Assuming final_df, X1, y, and PanelSplit are defined similarly to your original setup.\n",
    "# For example, PanelSplit could be a custom cross-validation generator for panel data.\n",
    "panel_split = PanelSplit(periods=final_df.year, n_splits=5)\n",
    "\n",
    "# To store cross-validation results\n",
    "cv_results = []\n",
    "\n",
    "# Global progress bar for cross-validation folds\n",
    "with tqdm(total=panel_split.n_splits, desc=\"Processing Folds with ThunderSVM\") as pbar:\n",
    "    for fold, (train_idx, test_idx) in enumerate(panel_split.split(X1)):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X1[train_idx], X1[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Define and train the ThunderSVM SVR model\n",
    "        # Here we use a basic RBF kernel; you can adjust parameters (C, epsilon, kernel, etc.) as needed.\n",
    "        svr_model = SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)\n",
    "        svr_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = svr_model.predict(X_train)\n",
    "        y_test_pred = svr_model.predict(X_test)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        mse = mean_squared_error(y_test, y_test_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Store the metrics for the current fold\n",
    "        cv_results.append({\n",
    "            \"fold\": fold,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2_test\": r2_test,\n",
    "            \"R2_train\": r2_train\n",
    "        })\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# Output the cross-validation results\n",
    "# ðŸ”¹ Compute Averages Across CV Splits\n",
    "avg_results = {metric: np.mean([fold[metric] for fold in cv_results]) for metric in cv_results[0].keys()}\n",
    "\n",
    "# ðŸ”¹ Print Results\n",
    "print(f\"âœ… XGBoost with PanelSplit Results:\")\n",
    "print(f\"ðŸ“Š Avg MSE: {avg_results['MSE']:.4f}\")\n",
    "print(f\"ðŸ“Š Avg RMSE: {avg_results['RMSE']:.4f}\")\n",
    "print(f\"ðŸ“Š Avg MAE: {avg_results['MAE']:.4f}\")\n",
    "print(f\"ðŸ“Š Avg RÂ² (Train): {avg_results['R2_train']:.4f}\")\n",
    "print(f\"ðŸ“Š Avg RÂ² (Test): {avg_results['R2_test']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Grid Search: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:14<00:00,  1.66s/it, ETA (sec)=0] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best Overall Parameters: {'C': 1.0, 'epsilon': 0.01, 'kernel': 'rbf'}\n",
      "ðŸ“Š Best Overall MSE: 0.0052\n",
      "ðŸ“Š Best Overall MAE: 0.0359\n",
      "ðŸ“Š Best Overall RMSE: 0.0714\n",
      "ðŸ“Š Best RÂ² (Train): 0.6582\n",
      "ðŸ“Š Best RÂ² (Test): 0.5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Option: use ThunderSVM if available (it supports GPU acceleration)\n",
    "try:\n",
    "    import os\n",
    "    os.add_dll_directory(r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.4\\bin\")\n",
    "    import thundersvm\n",
    "    from thundersvm import SVR as ThunderSVR\n",
    "    use_gpu = True\n",
    "except ImportError:\n",
    "    from sklearn.svm import SVR as ThunderSVR  # fallback to CPU if ThunderSVM is not installed\n",
    "    use_gpu = False\n",
    "\n",
    "\n",
    "# Define your parameter grid.\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1.0, 10.0],\n",
    "    \"epsilon\": [0.01, 0.1, 1.0],\n",
    "    \"kernel\": [\"rbf\"]\n",
    "}\n",
    "\n",
    "# Total iterations: number of parameter combinations * number of CV folds.\n",
    "param_list = list(ParameterGrid(param_grid))\n",
    "n_folds = panel_split.n_splits  # Assuming panel_split is defined.\n",
    "total_iterations = len(param_list) * n_folds\n",
    "\n",
    "# Container for results.\n",
    "results = []\n",
    "\n",
    "# Initialize tqdm progress bar.\n",
    "pbar = tqdm(total=total_iterations, desc=\"Running Grid Search\")\n",
    "\n",
    "# Start time to estimate running time.\n",
    "start_time = time.time()\n",
    "\n",
    "for params in param_list:\n",
    "    fold_metrics = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(panel_split.split(X1)):\n",
    "        # Split the data.\n",
    "        X_train, X_test = X1[train_idx], X1[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Initialize model with current parameters.\n",
    "        model = ThunderSVR(**params)\n",
    "        \n",
    "        # Fit model.\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions.\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Compute metrics.\n",
    "        mse = mean_squared_error(y_test, y_test_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2_train\": r2_train,\n",
    "            \"R2_test\": r2_test\n",
    "        })\n",
    "        \n",
    "        # Update progress bar after each fold.\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Compute average metrics for current parameters.\n",
    "    avg_metrics = {metric: np.mean([fold[metric] for fold in fold_metrics])\n",
    "                   for metric in fold_metrics[0].keys()}\n",
    "    \n",
    "    results.append({\n",
    "        \"params\": params,\n",
    "        \"metrics\": avg_metrics\n",
    "    })\n",
    "    \n",
    "    # Optional: Estimate remaining time.\n",
    "    elapsed = time.time() - start_time\n",
    "    iterations_done = pbar.n\n",
    "    avg_time_per_iter = elapsed / iterations_done\n",
    "    remaining_time = avg_time_per_iter * (total_iterations - iterations_done)\n",
    "    pbar.set_postfix({\"ETA (sec)\": int(remaining_time)})\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Select the best model based on RMSE.\n",
    "best_model = min(results, key=lambda x: x['metrics'][\"RMSE\"])\n",
    "\n",
    "# Print summary.\n",
    "print(\"âœ… Best Overall Parameters:\", best_model['params'])\n",
    "print(\"ðŸ“Š Best Overall MSE: {:.4f}\".format(best_model['metrics']['MSE']))\n",
    "print(\"ðŸ“Š Best Overall MAE: {:.4f}\".format(best_model['metrics']['MAE']))\n",
    "print(\"ðŸ“Š Best Overall RMSE: {:.4f}\".format(best_model['metrics']['RMSE']))\n",
    "print(\"ðŸ“Š Best RÂ² (Train): {:.4f}\".format(best_model['metrics']['R2_train']))\n",
    "print(\"ðŸ“Š Best RÂ² (Test): {:.4f}\".format(best_model['metrics']['R2_test']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
