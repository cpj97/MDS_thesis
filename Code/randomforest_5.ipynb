{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roandom Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:11.635852Z",
     "iopub.status.busy": "2025-03-12T09:07:11.635460Z",
     "iopub.status.idle": "2025-03-12T09:07:19.489740Z",
     "shell.execute_reply": "2025-03-12T09:07:19.488687Z",
     "shell.execute_reply.started": "2025-03-12T09:07:11.635823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#!pip install panelsplit\n",
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:19.491696Z",
     "iopub.status.busy": "2025-03-12T09:07:19.491359Z",
     "iopub.status.idle": "2025-03-12T09:07:19.497614Z",
     "shell.execute_reply": "2025-03-12T09:07:19.496644Z",
     "shell.execute_reply.started": "2025-03-12T09:07:19.491669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "import random\n",
    "\n",
    "from panelsplit.cross_validation import PanelSplit\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit  # Alternative to PanelSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Activate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCUDA Available:\u001b[39m\u001b[33m\"\u001b[39m, torch.cuda.is_available())\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGPU Name:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Check if GPU is available\u001b[39;00m\n\u001b[32m      7\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\torch\\cuda\\__init__.py:491\u001b[39m, in \u001b[36mget_device_name\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_name\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[32m    481\u001b[39m \n\u001b[32m    482\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m \u001b[33;03m        str: the name of the device\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[39m, in \u001b[36mget_device_properties\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_properties\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> _CudaDeviceProperties:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[32m    513\u001b[39m \n\u001b[32m    514\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m \u001b[33;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[32m    524\u001b[39m     device = _get_device_index(device, optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device >= device_count():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\torch\\cuda\\__init__.py:319\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    318\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    323\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check working directory\n",
    "#print(os.getcwd()) \n",
    "\n",
    "### Define file and path\n",
    "#file_path = r\"c:\\Users\\mmier\\OneDrive - Hertie School\\3. Estudio\\2025 MDS\\2025-1 MDS Thesis\\MDS_thesis\\Data\" #Use a raw string (r\"\") when defining paths\n",
    "#print(os.listdir(file_path)) # List files in directory\n",
    "csv_filename = \"../final_df.csv\"\n",
    "zip_filename = \"../final_df.zip\"\n",
    "#full_path = os.path.join(file_path, csv_filename)\n",
    "\n",
    "# Extract the CSV file from the ZIP\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zipf:\n",
    "    zipf.extract(csv_filename)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "final_df = pd.read_csv(\"final_df.csv\")\n",
    "\n",
    "# Delete the extracted CSV file after reading\n",
    "os.remove(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Define train, test and evaluation set\n",
    "\n",
    "Evaluation set: 2019 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate evaluation set \n",
    "#final_df = df[df[\"AÑO\"] < 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define y and X1\n",
    "\n",
    "y: deforestation\n",
    "\n",
    "X1: general variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y \n",
    "y = final_df['pc_loss']\n",
    "y = np.log1p(final_df['pc_loss'])\n",
    "y = y.to_numpy()\n",
    "\n",
    "# Normalize output\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# X final\n",
    "X1 = final_df.drop(columns=['year', 'codmpio', 'cluster_kmeans', 'Departamento', 'Municipio', 'Region', 'pc_loss', 'f_loss', 'areaoficialhm2', 'gdp']) # GDP, area already out since the were already considered\n",
    "X1 = X1.drop(columns=['CV-01-15','CV-03-64', 'CV-03-26b', 'CV-01-11', 'CV-01-1', 'PCC-02-0', 'PCC-02-3', 'EIS-00-0', 'PCC-00-0', 'CTI-00-0', 'C-02-8t', 'ICM-00-0',\n",
    "                      'EIS-03-4', 'CTI-01-3', 'SEG-00-0', 'SEG-01-6', 'SOS-00-0', 'SOS-02-0', 'SOS-02-2', 'SOS-01-6', 'GPI-00-0', 'GPI-02-4', 'GPI-02-5', 'P-01-34-1',\n",
    "                      'P-01-46', 'P-01-25', 'CV-02-12e', 'CV-03-51', 'total_ac']) \n",
    "\n",
    "\n",
    "# Keep feature names\n",
    "original_feature_names = list(X1.columns) \n",
    "\n",
    "# Normalize features\n",
    "#X1 = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Panel Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Define splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from panelsplit.cross_validation import PanelSplit\n",
    "\n",
    "### Initialize PanelSplit\n",
    "panel_split = PanelSplit(periods=final_df.year, n_splits=5)\n",
    "splits = panel_split.split()\n",
    "\n",
    "### Check splits, for n_splits=3\n",
    "splits_1_train = final_df.loc[splits[0][0]]\n",
    "splits_1_test = final_df.loc[splits[0][1]]\n",
    "splits_2_train = final_df.loc[splits[1][0]]\n",
    "splits_2_test = final_df.loc[splits[1][1]]\n",
    "splits_3_train = final_df.loc[splits[2][0]]\n",
    "splits_3_test = final_df.loc[splits[2][1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Train a Quick Random Forest to Identify Important Features\n",
    "\n",
    "Before running the full model, we train a baseline Random Forest to rank feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  Importance\n",
      "0  ICM-00-0    0.196626\n",
      "3  EIS-00-0    0.164162\n",
      "2  GPI-00-0    0.155989\n",
      "4  CTI-00-0    0.139145\n",
      "1  PCC-00-0    0.138938\n",
      "6  SOS-00-0    0.115721\n",
      "5  SEG-00-0    0.089419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Define a baseline Random Forest model\n",
    "rf_baseline = RandomForestRegressor(\n",
    "    n_estimators=50,  # Small number of trees for quick evaluation\n",
    "    max_depth=10,     # Limit tree depth to avoid overfitting\n",
    "    random_state=17,\n",
    "    n_jobs=-1         # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model on the full dataset (ignoring \"AÑO\" and \"Municipio\" for now)\n",
    "y = df_final[\"M-03-25\"]\n",
    "X = df_final.drop(columns=[\"M-03-25\", \"Divipola\", \"AÑO\"])  # Remove non-predictive ID variables\n",
    "rf_baseline.fit(X, y)\n",
    "\n",
    "# Extract feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": rf_baseline.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Display the top 30 features\n",
    "print(feature_importance_df.head(30))\n",
    "#import ace_tools as tools\n",
    "#tools.display_dataframe_to_user(name=\"Top Feature Importance\", dataframe=feature_importance_df.head(3))\n",
    "\n",
    "\n",
    "\n",
    "# Keep only the top 30 most important features\n",
    "#top_features = feature_importance_df[\"Feature\"].head(30).tolist()\n",
    "\n",
    "\n",
    "# Update X1 to only include the top features\n",
    "#X1 = X1[top_features]\n",
    "\n",
    "#print(f\"✅ Selected top {len(top_features)} features for the final model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.  Train the Final Random Forest Model\n",
    "\n",
    "\"Manual tunning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌲 Best Random Forest Parameters: n_estimators=300, max_depth=5\n",
      "📊 Best MSE: 739947.8996\n",
      "📊 Best RMSE: 839.6786\n",
      "📊 Best MAE: 174.8199\n",
      "📊 R² (Train): 0.2308\n",
      "📊 R² (Test): 0.0281\n",
      "📊 Adj. R² (Train): 0.2303\n",
      "📊 Adj. R² (Test): 0.0220\n"
     ]
    }
   ],
   "source": [
    "### Adjusted R² function\n",
    "def adjusted_r2(r2, n, k):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "### Define hyperparameters for tuning\n",
    "n_estimators_values = [50, 100, 200, 300]  # Number of decision trees in the Random Forest model\n",
    "max_depth_values = [5, 10, 20, None]       # Maximum depth of each tree (controls complexity)\n",
    "\n",
    "### Initialize Storage for Results\n",
    "results = {}\n",
    "\n",
    "### Setup panle data cross validation with  PanelSplit\n",
    "panel_split = PanelSplit(periods=df_final.AÑO, n_splits=3, gap=0, test_size=1)\n",
    "groups = X.index  # Using index since Municipio was dropped\n",
    "\n",
    "### Loop through Cross-Validation Splits\n",
    "for train_idx, test_idx in panel_split.split(X, y):\n",
    "#panel_split.split(X, y) iterates through each fold, providing indices for training and testing\n",
    "    \n",
    "    ## Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    ## Loop over hyperparameters combination\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            \n",
    "            # Define the Random Forest model\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                random_state=17,\n",
    "                n_jobs=-1  # Use all available processors\n",
    "            )\n",
    "            \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predictions\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            # Compute performance metrics\n",
    "            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "            mse = mean_squared_error(y_test, y_test_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            r2_test = r2_score(y_test, y_test_pred)\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            # Compute Adjusted R²\n",
    "            n_train, k = X_train.shape\n",
    "            n_test = X_test.shape[0]\n",
    "            adj_r2_train = adjusted_r2(r2_train, n_train, k)\n",
    "            adj_r2_test = adjusted_r2(r2_test, n_test, k)\n",
    "\n",
    "            # Store results\n",
    "            if (n_estimators, max_depth) not in results:\n",
    "                results[(n_estimators, max_depth)] = []\n",
    "\n",
    "            results[(n_estimators, max_depth)].append({\n",
    "                \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2_test\": r2_test, \"R2_train\": r2_train, \"Adj_R2_test\": adj_r2_test, \"Adj_R2_train\": adj_r2_train\n",
    "            })\n",
    "\n",
    "### Compute Average Performance Across Folds\n",
    "averaged_results = {\n",
    "    params: {metric: np.mean([fold[metric] for fold in folds])\n",
    "             for metric in folds[0].keys()}\n",
    "    for params, folds in results.items()\n",
    "}\n",
    "\n",
    "### Find the best hyperparameter combination\n",
    "best_params = min(averaged_results, key=lambda x: (averaged_results[x][\"MSE\"], -averaged_results[x][\"R2_test\"]))\n",
    "best_metrics = averaged_results[best_params]\n",
    "\n",
    "### Print optimal hyperparameters and performance\n",
    "print(f\"🌲 Best Random Forest Parameters: n_estimators={best_params[0]}, max_depth={best_params[1]}\")\n",
    "print(f\"📊 Best MSE: {best_metrics['MSE']:.4f}\")\n",
    "print(f\"📊 Best RMSE: {best_metrics['RMSE']:.4f}\")\n",
    "print(f\"📊 Best MAE: {best_metrics['MAE']:.4f}\")\n",
    "print(f\"📊 R² (Train): {best_metrics['R2_train']:.4f}\")\n",
    "print(f\"📊 R² (Test): {best_metrics['R2_test']:.4f}\")\n",
    "print(f\"📊 Adj. R² (Train): {best_metrics['Adj_R2_train']:.4f}\")\n",
    "print(f\"📊 Adj. R² (Test): {best_metrics['Adj_R2_test']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌲 Best Random Forest Parameters: n_estimators=300, max_depth=5\n",
    "📊 Best MSE: 739947.8996\n",
    "📊 Best RMSE: 839.6786\n",
    "📊 Best MAE: 174.8199\n",
    "📊 R² (Train): 0.2308\n",
    "📊 R² (Test): 0.0281\n",
    "📊 Adj. R² (Train): 0.2303\n",
    "📊 Adj. R² (Test): 0.0220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     28\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     29\u001b[39m     estimator=model,\n\u001b[32m     30\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Run grid search\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Extract best model and hyperparameters\u001b[39;00m\n\u001b[32m     41\u001b[39m best_params = grid_search.best_params_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mmier\\anaconda3\\envs\\MDS_thesis\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "### Adjusted R² function\n",
    "def adjusted_r2(r2, n, k):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "### Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500, 700],  \n",
    "    \"max_depth\": [5, 10, 20],  \n",
    "    \"min_samples_split\": [2, 5, 10],  \n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "### Setup panel data cross-validation\n",
    "panel_split = PanelSplit(periods=df_final.AÑO, n_splits=3, gap=0, test_size=1)\n",
    "groups = X.index  # Using index since Municipio was dropped\n",
    "\n",
    "# Define the RandomForestRegressor model\n",
    "model = RandomForestRegressor(random_state=17, n_jobs=-1)\n",
    "\n",
    "# Setup GridSearchCV with PanelSplit cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",  # Minimize MSE\n",
    "    cv=panel_split.split(X, y),  # Custom panel CV\n",
    "    n_jobs=-1,  # Parallel computation\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Extract best model and hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Store results for best hyperparameters\n",
    "results = []\n",
    "\n",
    "# Iterate through each fold for evaluation\n",
    "for train_idx, test_idx in panel_split.split(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train the best model on the current fold\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Compute Adjusted R²\n",
    "    n_train, k = X_train.shape\n",
    "    n_test = X_test.shape[0]\n",
    "    adj_r2_train = adjusted_r2(r2_train, n_train, k)\n",
    "    adj_r2_test = adjusted_r2(r2_test, n_test, k)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"MSE\": mse_test,\n",
    "        \"RMSE\": rmse_test,\n",
    "        \"MAE\": mae_test,\n",
    "        \"R2_train\": r2_train,\n",
    "        \"R2_test\": r2_test,\n",
    "        \"Adj_R2_train\": adj_r2_train,\n",
    "        \"Adj_R2_test\": adj_r2_test\n",
    "    })\n",
    "\n",
    "# Compute average performance across folds\n",
    "best_metrics = {metric: np.mean([fold[metric] for fold in results]) for metric in results[0].keys()}\n",
    "\n",
    "### Print optimal hyperparameters and performance\n",
    "print(f\"🌲 Best Random Forest Parameters: n_estimators={best_params['n_estimators']}, max_depth={best_params['max_depth']}\")\n",
    "print(f\"📊 Best MSE: {best_metrics['MSE']:.4f}\")\n",
    "print(f\"📊 Best RMSE: {best_metrics['RMSE']:.4f}\")\n",
    "print(f\"📊 Best MAE: {best_metrics['MAE']:.4f}\")\n",
    "print(f\"📊 R² (Train): {best_metrics['R2_train']:.4f}\")\n",
    "print(f\"📊 R² (Test): {best_metrics['R2_test']:.4f}\")\n",
    "print(f\"📊 Adj. R² (Train): {best_metrics['Adj_R2_train']:.4f}\")\n",
    "print(f\"📊 Adj. R² (Test): {best_metrics['Adj_R2_test']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n",
    "🌲 Best Random Forest Parameters: n_estimators=700, max_depth=None\n",
    "📊 Best MSE: 709110.1742\n",
    "📊 Best RMSE: 821.6917\n",
    "📊 Best MAE: 170.5814\n",
    "📊 R² (Train): 0.4968\n",
    "📊 R² (Test): 0.0701\n",
    "📊 Adj. R² (Train): 0.4965\n",
    "📊 Adj. R² (Test): 0.0642 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "🌲 Best Random Forest Parameters: n_estimators=853, max_depth=20\n",
      "📊 Best MSE: 706687.1554\n",
      "📊 Best RMSE: 819.8642\n",
      "📊 Best MAE: 168.8173\n",
      "📊 R² (Train): 0.3132\n",
      "📊 R² (Test): 0.0754\n",
      "📊 Adj. R² (Train): 0.3128\n",
      "📊 Adj. R² (Test): 0.0696\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "### Adjusted R² function\n",
    "def adjusted_r2(r2, n, k):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "### Define hyperparameter space\n",
    "param_distributions = {\n",
    "    \"n_estimators\": np.random.randint(100, 1000, 10).tolist(),  # Random values from 100 to 1000\n",
    "    \"max_depth\": [3, 5, 10, 20, None],  \n",
    "    \"min_samples_split\": np.random.randint(2, 15, 5).tolist(),  \n",
    "    \"min_samples_leaf\": np.random.randint(1, 10, 5).tolist()\n",
    "}\n",
    "\n",
    "### Setup panel data cross-validation\n",
    "panel_split = PanelSplit(periods=df_final.AÑO, n_splits=3, gap=0, test_size=1)\n",
    "groups = X.index  # Using index since Municipio was dropped\n",
    "\n",
    "# Define the RandomForestRegressor model\n",
    "model = RandomForestRegressor(random_state=17, n_jobs=-1)\n",
    "\n",
    "# Setup RandomizedSearchCV with PanelSplit cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of random samples to try\n",
    "    scoring=\"neg_mean_squared_error\",  # Minimize MSE\n",
    "    cv=panel_split.split(X, y),  # Custom panel CV\n",
    "    n_jobs=-1,  # Parallel computation\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Run random search\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Extract best model and hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Store results for best hyperparameters\n",
    "results = []\n",
    "\n",
    "# Iterate through each fold for evaluation\n",
    "for train_idx, test_idx in panel_split.split(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train the best model on the current fold\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Compute Adjusted R²\n",
    "    n_train, k = X_train.shape\n",
    "    n_test = X_test.shape[0]\n",
    "    adj_r2_train = adjusted_r2(r2_train, n_train, k)\n",
    "    adj_r2_test = adjusted_r2(r2_test, n_test, k)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"MSE\": mse_test,\n",
    "        \"RMSE\": rmse_test,\n",
    "        \"MAE\": mae_test,\n",
    "        \"R2_train\": r2_train,\n",
    "        \"R2_test\": r2_test,\n",
    "        \"Adj_R2_train\": adj_r2_train,\n",
    "        \"Adj_R2_test\": adj_r2_test\n",
    "    })\n",
    "\n",
    "# Compute average performance across folds\n",
    "best_metrics = {metric: np.mean([fold[metric] for fold in results]) for metric in results[0].keys()}\n",
    "\n",
    "### Print optimal hyperparameters and performance\n",
    "print(f\"🌲 Best Random Forest Parameters: n_estimators={best_params['n_estimators']}, max_depth={best_params['max_depth']}\")\n",
    "print(f\"📊 Best MSE: {best_metrics['MSE']:.4f}\")\n",
    "print(f\"📊 Best RMSE: {best_metrics['RMSE']:.4f}\")\n",
    "print(f\"📊 Best MAE: {best_metrics['MAE']:.4f}\")\n",
    "print(f\"📊 R² (Train): {best_metrics['R2_train']:.4f}\")\n",
    "print(f\"📊 R² (Test): {best_metrics['R2_test']:.4f}\")\n",
    "print(f\"📊 Adj. R² (Train): {best_metrics['Adj_R2_train']:.4f}\")\n",
    "print(f\"📊 Adj. R² (Test): {best_metrics['Adj_R2_test']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
    "🌲 Best Random Forest Parameters: n_estimators=853, max_depth=20\n",
    "📊 Best MSE: 706687.1554\n",
    "📊 Best RMSE: 819.8642\n",
    "📊 Best MAE: 168.8173\n",
    "📊 R² (Train): 0.3132\n",
    "📊 R² (Test): 0.0754\n",
    "📊 Adj. R² (Train): 0.3128\n",
    "📊 Adj. R² (Test): 0.0696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6837566,
     "sourceId": 10985952,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "MDS_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
