{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:11.635852Z",
     "iopub.status.busy": "2025-03-12T09:07:11.635460Z",
     "iopub.status.idle": "2025-03-12T09:07:19.489740Z",
     "shell.execute_reply": "2025-03-12T09:07:19.488687Z",
     "shell.execute_reply.started": "2025-03-12T09:07:11.635823Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: panelsplit in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from panelsplit) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panelsplit) (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from panelsplit) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from panelsplit) (3.7.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from panelsplit) (1.4.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from panelsplit) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->panelsplit) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->panelsplit) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->panelsplit) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->panelsplit) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->panelsplit) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->panelsplit) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->panelsplit) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->panelsplit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->panelsplit) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->panelsplit) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->panelsplit) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->panelsplit) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->panelsplit) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->panelsplit) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->panelsplit) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->panelsplit) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->panelsplit) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install panelsplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:19.491696Z",
     "iopub.status.busy": "2025-03-12T09:07:19.491359Z",
     "iopub.status.idle": "2025-03-12T09:07:19.497614Z",
     "shell.execute_reply": "2025-03-12T09:07:19.496644Z",
     "shell.execute_reply.started": "2025-03-12T09:07:19.491669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "import random\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from panelsplit.cross_validation import PanelSplit\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:19.499458Z",
     "iopub.status.busy": "2025-03-12T09:07:19.499180Z",
     "iopub.status.idle": "2025-03-12T09:07:19.514457Z",
     "shell.execute_reply": "2025-03-12T09:07:19.513437Z",
     "shell.execute_reply.started": "2025-03-12T09:07:19.499433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")  # Check if GPU or CPU is being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:19.516215Z",
     "iopub.status.busy": "2025-03-12T09:07:19.515863Z",
     "iopub.status.idle": "2025-03-12T09:07:23.923962Z",
     "shell.execute_reply": "2025-03-12T09:07:23.923025Z",
     "shell.execute_reply.started": "2025-03-12T09:07:19.516183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codmpio</th>\n",
       "      <th>year</th>\n",
       "      <th>tc_loss</th>\n",
       "      <th>gandina</th>\n",
       "      <th>gcaribe</th>\n",
       "      <th>gpacifica</th>\n",
       "      <th>gorinoquia</th>\n",
       "      <th>gamazonia</th>\n",
       "      <th>areaoficialhm2</th>\n",
       "      <th>discapital</th>\n",
       "      <th>...</th>\n",
       "      <th>subnational1_VAUPES</th>\n",
       "      <th>subnational1_VICHADA</th>\n",
       "      <th>cluster_kmeans_0</th>\n",
       "      <th>cluster_kmeans_1</th>\n",
       "      <th>cluster_kmeans_2</th>\n",
       "      <th>cluster_kmeans_3</th>\n",
       "      <th>cluster_kmeans_4</th>\n",
       "      <th>cluster_kmeans_5</th>\n",
       "      <th>cluster_kmeans_6</th>\n",
       "      <th>tc_loss_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5873.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5873.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>18.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5873.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>13.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5873.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>10.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5873.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>23.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 1273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   codmpio    year  tc_loss  gandina  gcaribe  gpacifica  gorinoquia  \\\n",
       "0   5873.0  2003.0    2.000      1.0      0.0        0.0         0.0   \n",
       "1   5873.0  2004.0   18.000      1.0      0.0        0.0         0.0   \n",
       "2   5873.0  2005.0   13.375      1.0      0.0        0.0         0.0   \n",
       "3   5873.0  2006.0   10.875      1.0      0.0        0.0         0.0   \n",
       "4   5873.0  2007.0   23.000      1.0      0.0        0.0         0.0   \n",
       "\n",
       "   gamazonia  areaoficialhm2  discapital  ...  subnational1_VAUPES  \\\n",
       "0        0.0        180100.0       122.0  ...                    0   \n",
       "1        0.0        180100.0       122.0  ...                    0   \n",
       "2        0.0        180100.0       122.0  ...                    0   \n",
       "3        0.0        180100.0       122.0  ...                    0   \n",
       "4        0.0        180100.0       122.0  ...                    0   \n",
       "\n",
       "   subnational1_VICHADA  cluster_kmeans_0  cluster_kmeans_1  cluster_kmeans_2  \\\n",
       "0                     0                 0                 0                 0   \n",
       "1                     0                 0                 0                 0   \n",
       "2                     0                 0                 0                 0   \n",
       "3                     0                 0                 0                 0   \n",
       "4                     0                 0                 0                 0   \n",
       "\n",
       "   cluster_kmeans_3  cluster_kmeans_4  cluster_kmeans_5  cluster_kmeans_6  \\\n",
       "0                 0                 0                 1                 0   \n",
       "1                 0                 0                 1                 0   \n",
       "2                 0                 0                 1                 0   \n",
       "3                 0                 0                 1                 0   \n",
       "4                 0                 0                 1                 0   \n",
       "\n",
       "   tc_loss_area  \n",
       "0      0.000011  \n",
       "1      0.000100  \n",
       "2      0.000074  \n",
       "3      0.000060  \n",
       "4      0.000128  \n",
       "\n",
       "[5 rows x 1273 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset path\n",
    "ds_path = \"/kaggle/input/final-ds\"\n",
    "\n",
    "# Create a list with the files in the dataset (dataframes)\n",
    "ds_files = os.listdir(ds_path) #list available files in the dataset\n",
    "\n",
    "# Load each file into a dictionary (assuming all files are csv)\n",
    "ds = {file: pd.read_csv(f\"{ds_path}/{file}\") for file in ds_files}\n",
    "\n",
    "# Create the specific dataframe\n",
    "final_df = ds[ds_files[0]] #first csv file\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:23.925137Z",
     "iopub.status.busy": "2025-03-12T09:07:23.924870Z",
     "iopub.status.idle": "2025-03-12T09:07:24.253388Z",
     "shell.execute_reply": "2025-03-12T09:07:24.252429Z",
     "shell.execute_reply.started": "2025-03-12T09:07:23.925116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Data after 2007\n",
    "final_df = final_df[final_df['year'] > 2006]\n",
    "# y \n",
    "y = final_df['tc_loss']\n",
    "\n",
    "# Normalize output\n",
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Get rid of columns that start with 'subnational1_' and 'cluster_' in train and test   \n",
    "#X1 = final_df.loc[:,~final_df.columns.str.startswith('g')]\n",
    "X1 = final_df.loc[:,~final_df.columns.str.startswith('subnational1_')]\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('cluster_')]\n",
    "\n",
    "\n",
    "# Get rid of all disaggregated columns\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('ac_')]\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('as_')]\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('p_')]\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('r_')]\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('nuf_')]\n",
    "X1 = X1.loc[:,~X1.columns.str.startswith('vrf_')]\n",
    "\n",
    "# X final\n",
    "X1 = X1.drop(columns=['year', 'tc_loss', 'tc_loss_area', 'codmpio'])\n",
    "\n",
    "# Keep feature names\n",
    "original_feature_names = list(X1.columns) \n",
    "\n",
    "# Create polynomial interaction terms (degree=2, only interactions, no bias term)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interactions = poly.fit_transform(X1)\n",
    "\n",
    "# Get the feature names including interactions\n",
    "interaction_feature_names = poly.get_feature_names_out(original_feature_names)\n",
    "\n",
    "# Compute standard deviation of each feature\n",
    "stds = X1.std(axis=0)\n",
    "\n",
    "# Find columns where std = 0\n",
    "zero_variance_features = np.where(stds == 0)[0]\n",
    "\n",
    "if len(zero_variance_features) > 0:\n",
    "    print(f\"‚ö†Ô∏è Removing {len(zero_variance_features)} features with zero variance.\")\n",
    "    print(f\"üîç Removed feature indices: {zero_variance_features}\")\n",
    "\n",
    "    # If feature names are available, print them\n",
    "    if isinstance(X1, pd.DataFrame):  # If X is a DataFrame\n",
    "        removed_feature_names = X1.columns[zero_variance_features]\n",
    "        print(f\"üìå Removed feature names: {list(removed_feature_names)}\")\n",
    "\n",
    "    X1 = np.delete(X1, zero_variance_features, axis=1)  # Remove constant columns\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "X1 = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:24.254575Z",
     "iopub.status.busy": "2025-03-12T09:07:24.254282Z",
     "iopub.status.idle": "2025-03-12T09:07:24.259770Z",
     "shell.execute_reply": "2025-03-12T09:07:24.258928Z",
     "shell.execute_reply.started": "2025-03-12T09:07:24.254533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LassoRegression(nn.Module):\n",
    "    def __init__(self, input_dim, l1_lambda=0.01):\n",
    "        super(LassoRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.l1_lambda = l1_lambda  # Regularization strength\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def l1_regularization_loss(self):\n",
    "        return self.l1_lambda * torch.norm(self.linear.weight, p=1)  # L1 Regularization (Lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:24.260944Z",
     "iopub.status.busy": "2025-03-12T09:07:24.260695Z",
     "iopub.status.idle": "2025-03-12T09:07:57.696975Z",
     "shell.execute_reply": "2025-03-12T09:07:57.696157Z",
     "shell.execute_reply.started": "2025-03-12T09:07:24.260920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Number of features after Polynomial Features: 120\n",
      "‚úÖ  Optimal L1 lambda: 1\n",
      "üìä Best MSE: 0.5431\n",
      "üìä Best RMSE: 0.7081\n",
      "üìä Best MAE: 0.2424\n",
      "üìä R¬≤ (Train): 0.5355, Adjusted R¬≤ (Train): 0.5316\n",
      "üìä R¬≤ (Test): 0.4552, Adjusted R¬≤ (Test): 0.3853\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_value = 17\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)  # If using GPU\n",
    "\n",
    "# Define TimeSeriesSplit (e.g., 5 splits)\n",
    "panel_split = PanelSplit(periods = final_df.year, n_splits = 5)\n",
    "\n",
    "# Hyperparameters\n",
    "lambda_values = [0.00001, 0.0001, 0.001, 0.01, 0.05, 1]  # Different L1 values\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "# Adjusted R¬≤ function\n",
    "def adjusted_r2(r2, n, k):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Dictionary to store results across all CV splits\n",
    "results = {}\n",
    "\n",
    "fold_results = []  # Store results for each fold\n",
    "\n",
    "# Perform TimeSeriesSplit Cross-Validation\n",
    "for train_idx, test_idx in panel_split.split(X1):\n",
    "\n",
    "    # Create interaction terms (degree=2 means pairwise interactions)\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    X_interactions = poly.fit_transform(X1)\n",
    "    \n",
    "    # Split dataset into train & test per fold\n",
    "    X_train1, X_test1 = X_interactions[train_idx], X_interactions[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor1 = torch.tensor(X_train1, dtype=torch.float32).to(device)\n",
    "    X_test_tensor1 = torch.tensor(X_test1, dtype=torch.float32).to(device)\n",
    "    y_tensor_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    y_tensor_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Train and evaluate for each lambda value\n",
    "    for l1_lambda in lambda_values:\n",
    "        model = LassoRegression(X_train_tensor1.shape[1], l1_lambda=l1_lambda).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_train_tensor1)\n",
    "            loss = criterion(y_pred, y_tensor_train) + model.l1_regularization_loss()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate on train & test sets\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_train_pred = model(X_train_tensor1)  # Training predictions\n",
    "            y_test_pred = model(X_test_tensor1)   # Test predictions\n",
    "\n",
    "        # Convert predictions to NumPy for evaluation\n",
    "        y_train_pred_numpy = y_train_pred.cpu().numpy().flatten()\n",
    "        y_test_pred_numpy = y_test_pred.cpu().numpy().flatten()\n",
    "        y_train_numpy = y_tensor_train.cpu().numpy().flatten()\n",
    "        y_test_numpy = y_tensor_test.cpu().numpy().flatten()\n",
    "\n",
    "        # Compute metrics\n",
    "        mse = mean_squared_error(y_test_numpy, y_test_pred_numpy)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test_numpy, y_test_pred_numpy)\n",
    "        r2_test = r2_score(y_test_numpy, y_test_pred_numpy)  # Test R¬≤\n",
    "        r2_train = r2_score(y_train_numpy, y_train_pred_numpy)  # Train R¬≤\n",
    "\n",
    "        # Compute Adjusted R¬≤\n",
    "        n_train, k = X_train1.shape\n",
    "        n_test = X_test1.shape[0]\n",
    "\n",
    "        adj_r2_train = adjusted_r2(r2_train, n_train, k)\n",
    "        adj_r2_test = adjusted_r2(r2_test, n_test, k)\n",
    "\n",
    "        # Store results for this fold\n",
    "        fold_results.append({\n",
    "            \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2_test\": r2_test, \"R2_train\": r2_train,\n",
    "            \"Adj_R2_test\": adj_r2_test, \"Adj_R2_train\": adj_r2_train\n",
    "        })\n",
    "\n",
    "# Compute average performance across all folds for each (k, lambda)\n",
    "avg_results = {\n",
    "    metric: np.mean([fold[metric] for fold in fold_results])\n",
    "    for metric in fold_results[0].keys()\n",
    "}\n",
    "results[(l1_lambda)] = avg_results\n",
    "\n",
    "# Find the best lambda\n",
    "best_lambda = min(results, key=lambda x: (results[x][\"MSE\"], -results[x][\"R2_test\"]))  # Minimize MSE, maximize R¬≤\n",
    "best_metrics = results[best_lambda]\n",
    "\n",
    "# Print optimal hyperparameters and their performance\n",
    "print(f\"üî¢ Number of features after Polynomial Features: {X_interactions.shape[1]}\")\n",
    "print(f\"‚úÖ  Optimal L1 lambda: {best_lambda}\")\n",
    "print(f\"üìä Best MSE: {best_metrics['MSE']:.4f}\")\n",
    "print(f\"üìä Best RMSE: {best_metrics['RMSE']:.4f}\")\n",
    "print(f\"üìä Best MAE: {best_metrics['MAE']:.4f}\")\n",
    "print(f\"üìä R¬≤ (Train): {best_metrics['R2_train']:.4f}, Adjusted R¬≤ (Train): {best_metrics['Adj_R2_train']:.4f}\")\n",
    "print(f\"üìä R¬≤ (Test): {best_metrics['R2_test']:.4f}, Adjusted R¬≤ (Test): {best_metrics['Adj_R2_test']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T09:07:57.699006Z",
     "iopub.status.busy": "2025-03-12T09:07:57.698765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit  # Alternative to PanelSplit\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_value = 17\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Define Time-Series Cross-Validation (5 splits)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Hyperparameters for Random Forest\n",
    "n_estimators_values = [50, 100, 200, 300]  # Number of trees to test\n",
    "max_depth_values = [5, 10, 20, None]  # Depth of trees\n",
    "\n",
    "# Function to compute Adjusted R¬≤\n",
    "def adjusted_r2(r2, n, k):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Perform Time-Series Cross-Validation\n",
    "for train_idx, test_idx in tscv.split(X1):\n",
    "    \n",
    "    # Create polynomial interaction terms (degree=2, only interactions)\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    X_interactions = poly.fit_transform(X1)\n",
    "\n",
    "    # Split dataset into train & test per fold\n",
    "    X_train1, X_test1 = X_interactions[train_idx], X_interactions[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Train and evaluate for each combination of hyperparameters\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            \n",
    "            # Define the Random Forest model\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                random_state=seed_value,\n",
    "                n_jobs=-1  # Use all available processors\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train1, y_train.ravel())\n",
    "\n",
    "            # Predictions\n",
    "            y_train_pred = model.predict(X_train1)\n",
    "            y_test_pred = model.predict(X_test1)\n",
    "\n",
    "            # Compute performance metrics\n",
    "            mse = mean_squared_error(y_test, y_test_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            r2_test = r2_score(y_test, y_test_pred)\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            # Compute Adjusted R¬≤\n",
    "            n_train, k = X_train1.shape\n",
    "            n_test = X_test1.shape[0]\n",
    "            adj_r2_train = adjusted_r2(r2_train, n_train, k)\n",
    "            adj_r2_test = adjusted_r2(r2_test, n_test, k)\n",
    "\n",
    "            # Store results for this combination\n",
    "            results[(n_estimators, max_depth)] = {\n",
    "                \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2_test\": r2_test, \"R2_train\": r2_train,\n",
    "                \"Adj_R2_test\": adj_r2_test, \"Adj_R2_train\": adj_r2_train\n",
    "            }\n",
    "\n",
    "# Find the best hyperparameter combination (minimize MSE, maximize R¬≤)\n",
    "best_params = min(results, key=lambda x: (results[x][\"MSE\"], -results[x][\"R2_test\"]))\n",
    "best_metrics = results[best_params]\n",
    "\n",
    "# Print optimal hyperparameters and their performance\n",
    "print(f\"üå≤ Optimal Random Forest Parameters: n_estimators={best_params[0]}, max_depth={best_params[1]}\")\n",
    "print(f\"üìä Best MSE: {best_metrics['MSE']:.4f}\")\n",
    "print(f\"üìä Best RMSE: {best_metrics['RMSE']:.4f}\")\n",
    "print(f\"üìä Best MAE: {best_metrics['MAE']:.4f}\")\n",
    "print(f\"üìä R¬≤ (Train): {best_metrics['R2_train']:.4f}, Adjusted R¬≤ (Train): {best_metrics['Adj_R2_train']:.4f}\")\n",
    "print(f\"üìä R¬≤ (Test): {best_metrics['R2_test']:.4f}, Adjusted R¬≤ (Test): {best_metrics['Adj_R2_test']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6837566,
     "sourceId": 10985952,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "MDS_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
